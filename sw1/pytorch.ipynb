{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f47b1b6f",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "In this exercise, we will look at some basic functionality of PyTorch. Your are free to use other DL frameworks for your exercises and your project. However, the master solutions and code examples will be in PyTorch.\n",
    "\n",
    "The [PyTorch documentation](https://pytorch.org/docs/stable/index.html) offers information on its functionality. A lot of the time, your specific question will also have been asked on the [PyTorch Forum](https://discuss.pytorch.org/), often with competent answers by the core developers (Google will find the relevant thread for you).\n",
    "\n",
    "First, we have to install PyTorch. We will install the basic version for this exercise. For your project, if you want to run on a GPU, you'll have to make sure to have a PyTorch version installed that is compatible with the CUDA version of your NVIDIA drivers. PyTorch has an [installation guide](https://pytorch.org/get-started/locally/) that will help you with getting the right version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15a1efca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m26.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q torch ipywidgets ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c05320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ec5791",
   "metadata": {},
   "source": [
    "## Tensor operations\n",
    "Most of PyTorch's operations have the same name as in NumPy. The basic object for storing data is the `torch.tensor`, the equivalent of the `np.array`. With the help of the [Tensor tutorial](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html), do the following:\n",
    "\n",
    "- Create a `torch.tensor` with the elements `[[1, 2], [3, 4]]`\n",
    "- Create a tensor of ones/zeros with the same shape and dtype\n",
    "- Create a random tensor of the same shape\n",
    "- Print the tensor's shape, data type and device\n",
    "- Try to move it to the GPU\n",
    "- For Mac users: Try to move it to [MPS](https://pytorch.org/docs/stable/notes/mps.html)\n",
    "- Check out indexing/slicing operations, and how you can assign values to a slice.\n",
    "- Combine tensors with `torch.cat` and `torch.stack`. What are the differences?\n",
    "- Multiply tensors, element-wise and with matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c90229fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.int64\n",
      "cpu\n",
      "\n",
      "\n",
      "torch.Size([2, 2])\n",
      "torch.int64\n",
      "cpu\n",
      "\n",
      "\n",
      "torch.Size([2, 2])\n",
      "torch.float32\n",
      "cpu\n",
      "\n",
      "\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[0, 2],\n",
      "        [1, 0]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor(\n",
    "    [[1, 2], [3, 4]]\n",
    ")\n",
    "\n",
    "t2 = torch.tensor(\n",
    "    [[0, 1], [1, 0]]\n",
    ")\n",
    "\n",
    "t3 = torch.rand(\n",
    "    2, 2\n",
    ")\n",
    "\n",
    "tensors = [t1, t2, t3]\n",
    "\n",
    "for tensor in tensors:\n",
    "    print(tensor.shape)\n",
    "    print(tensor.dtype)\n",
    "    print(tensor.device)\n",
    "    print(\"\\n\")\n",
    "\n",
    "t1[:, 1]\n",
    "t2[0,1] = 2\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f5e41b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not available :c\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"available\")\n",
    "else:\n",
    "    print(\"not available :c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473d3a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [0, 2],\n",
      "        [1, 0]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = torch.cat((t1, t2))\n",
    "print(cat)\n",
    "cat.dim_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a74769b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2],\n",
      "         [3, 4]],\n",
      "\n",
      "        [[0, 2],\n",
      "         [1, 0]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 1, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stack = torch.stack((t1,t2))\n",
    "print(stack)\n",
    "stack.dim_order()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "273ac131",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 4],\n",
       "        [3, 0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 * t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce942ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [4, 6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 @ t2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d36d91f",
   "metadata": {},
   "source": [
    "## Neural Network Basics\n",
    "Solve the followings tasks with the help of the [Neural networks tutorial](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html).\n",
    "\n",
    "The `nn.Module` is the basic class for layers, networks and models. All parameters of an `nn.Module` are automatically discovered by PyTorch and updated by back-propagation.\n",
    "\n",
    "First, define a neural network (as a subclass of `nn.Module`) with two linear layers and a ReLU non-linearity in between. Make the input, output, and inner dimensions parameters of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5284525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e66e191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_dim=42, hidden_dim=69, output_dim=420):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x1 = self.l1(input)\n",
    "        x2 = self.relu(x1)\n",
    "        x3 = self.l2(x2)\n",
    "        return x3\n",
    "    \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36eae143",
   "metadata": {},
   "source": [
    "Move the entire network to the GPU/MPS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f976d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cuda :c\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    net.to(\"cuda\") \n",
    "else:\n",
    "    print(\"No cuda :c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b22867b",
   "metadata": {},
   "source": [
    "Print the parameters of your network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e3383e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.0065, -0.0241,  0.1095,  ...,  0.1095, -0.0163,  0.1351],\n",
      "        [ 0.1217, -0.1534,  0.0003,  ..., -0.0576, -0.0865, -0.0031],\n",
      "        [ 0.0331, -0.0644,  0.0784,  ...,  0.0056,  0.0756,  0.1277],\n",
      "        ...,\n",
      "        [ 0.0846,  0.0946, -0.0841,  ..., -0.0503, -0.1408, -0.0176],\n",
      "        [-0.0277,  0.0392,  0.0099,  ...,  0.0381, -0.0529, -0.0884],\n",
      "        [ 0.1274, -0.1401,  0.0632,  ...,  0.1154,  0.0602, -0.1384]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([ 0.0033,  0.1407, -0.0422,  0.1472, -0.0985,  0.0067,  0.0648,  0.0216,\n",
      "         0.0686, -0.0852,  0.1180, -0.0174, -0.0682,  0.0112,  0.1213,  0.0916,\n",
      "         0.1012, -0.0359,  0.1080, -0.1393,  0.1123, -0.0689,  0.1150, -0.0565,\n",
      "         0.1219, -0.0262, -0.1212, -0.1028,  0.0341,  0.1283,  0.1070, -0.0266,\n",
      "         0.0511, -0.0678,  0.0561, -0.0480,  0.0328, -0.0886,  0.0169, -0.1474,\n",
      "         0.1162, -0.1476, -0.1298, -0.0662, -0.0156, -0.1537,  0.0349,  0.1211,\n",
      "        -0.0922,  0.1421,  0.0466, -0.0212, -0.0497,  0.0801, -0.1090,  0.1022,\n",
      "         0.0952,  0.0180,  0.1333, -0.0963,  0.1019,  0.1125, -0.1341,  0.0768,\n",
      "         0.1422,  0.1453, -0.0535,  0.0381,  0.1529], requires_grad=True), Parameter containing:\n",
      "tensor([[-0.0560,  0.0101,  0.0653,  ..., -0.0432,  0.0661,  0.1028],\n",
      "        [-0.0423, -0.0831, -0.0492,  ...,  0.0125, -0.1048,  0.0695],\n",
      "        [-0.0246,  0.1008,  0.0746,  ..., -0.0828, -0.0085, -0.0002],\n",
      "        ...,\n",
      "        [ 0.0347,  0.0749, -0.0483,  ..., -0.0817,  0.0640,  0.1156],\n",
      "        [-0.1172,  0.0816,  0.0172,  ...,  0.1118, -0.1168,  0.0553],\n",
      "        [-0.0290,  0.0258,  0.0621,  ...,  0.0357,  0.0349, -0.1040]],\n",
      "       requires_grad=True), Parameter containing:\n",
      "tensor([-0.0735, -0.1076, -0.0665, -0.0594, -0.0131, -0.0027,  0.0534,  0.0794,\n",
      "         0.0770, -0.0542, -0.0824,  0.0735, -0.0758, -0.0580,  0.0391, -0.0462,\n",
      "         0.0035,  0.1095, -0.0005, -0.0750, -0.0141,  0.0269, -0.1155,  0.0993,\n",
      "         0.1082,  0.0543,  0.0252, -0.0751,  0.1166, -0.0638,  0.1198, -0.0380,\n",
      "        -0.0135,  0.0030, -0.0955,  0.0096, -0.0045, -0.0833,  0.0662,  0.0304,\n",
      "        -0.0007,  0.0521, -0.0108, -0.1175, -0.0733, -0.0451,  0.0123,  0.0580,\n",
      "        -0.0376,  0.0952, -0.0709, -0.0486,  0.0290,  0.0472, -0.0194, -0.0129,\n",
      "        -0.0491,  0.0879,  0.1100, -0.0030, -0.1096, -0.1201, -0.0311,  0.0617,\n",
      "        -0.0350,  0.0786, -0.0202,  0.0998,  0.0002, -0.0130,  0.0759,  0.1081,\n",
      "        -0.0868,  0.0771, -0.0903, -0.0619,  0.0340, -0.0975,  0.0278,  0.0396,\n",
      "         0.0349, -0.0360,  0.0762,  0.1048, -0.0709,  0.0447, -0.0654,  0.0486,\n",
      "         0.0077,  0.0467,  0.0978,  0.0425, -0.0362, -0.0419,  0.0354,  0.0742,\n",
      "        -0.0954,  0.0249,  0.1157,  0.0194, -0.0945, -0.0102,  0.0903, -0.0741,\n",
      "        -0.0996, -0.0666, -0.0613, -0.1158,  0.0518,  0.0647, -0.0333, -0.0906,\n",
      "         0.0297,  0.0284, -0.0391,  0.1029,  0.0154, -0.0972,  0.0756, -0.1161,\n",
      "        -0.0836, -0.0123,  0.0130,  0.0474,  0.0946, -0.0561,  0.1065,  0.0394,\n",
      "        -0.0042,  0.0892,  0.0018,  0.0677,  0.0092, -0.1146,  0.0074,  0.0845,\n",
      "        -0.0135,  0.0999,  0.0871, -0.0241,  0.0046, -0.0953,  0.0058, -0.0590,\n",
      "         0.0725,  0.0704, -0.0188, -0.0787, -0.0540, -0.0615,  0.1190, -0.0122,\n",
      "        -0.0724,  0.0015, -0.0630, -0.0743,  0.0901,  0.0963, -0.0205, -0.0654,\n",
      "         0.1065, -0.0585, -0.0219, -0.0778, -0.0444,  0.0771,  0.0524, -0.0679,\n",
      "         0.0874, -0.0059, -0.0968,  0.0107,  0.0337,  0.0846,  0.0490,  0.0474,\n",
      "        -0.0914, -0.0602,  0.0985, -0.0689, -0.0567, -0.1201,  0.0461,  0.1002,\n",
      "         0.0890, -0.0095, -0.0139, -0.0506, -0.1143,  0.0315, -0.0950,  0.1139,\n",
      "         0.0523, -0.0307,  0.0022,  0.1117, -0.0741,  0.0508, -0.1084,  0.0835,\n",
      "         0.0115,  0.1118,  0.0140, -0.1194,  0.1015,  0.1000,  0.0090, -0.0770,\n",
      "        -0.0923, -0.1136, -0.0290, -0.0496,  0.1077,  0.0468,  0.1184, -0.0600,\n",
      "        -0.0134, -0.0805, -0.0712,  0.0683, -0.0847,  0.0316, -0.0084,  0.0962,\n",
      "         0.0251, -0.0367, -0.0019, -0.0834, -0.0920,  0.0207, -0.0393,  0.1202,\n",
      "         0.1182, -0.0062, -0.0886, -0.0341, -0.0788, -0.0782,  0.0212,  0.1181,\n",
      "         0.0525, -0.0035, -0.1048,  0.0506, -0.0572,  0.1095, -0.0909,  0.0215,\n",
      "        -0.1167,  0.0112, -0.0640, -0.1015, -0.0095,  0.0584,  0.0654, -0.1153,\n",
      "        -0.0424, -0.0564,  0.0968, -0.0122, -0.0506,  0.0921, -0.1022, -0.0028,\n",
      "         0.0079,  0.1132, -0.1149, -0.0288, -0.0496,  0.1050,  0.0725,  0.0228,\n",
      "        -0.0056, -0.0493, -0.1171, -0.0893,  0.0586, -0.0016, -0.0876,  0.0433,\n",
      "         0.0066, -0.0460, -0.1037,  0.0928, -0.0039, -0.0014, -0.0005,  0.0218,\n",
      "        -0.0228, -0.1161, -0.1175,  0.0950,  0.0980,  0.0301, -0.1153, -0.0731,\n",
      "         0.1185, -0.0255,  0.0882,  0.1025, -0.0599,  0.0364,  0.0120,  0.0876,\n",
      "         0.0180,  0.0327, -0.0311,  0.0685,  0.0434,  0.0492, -0.0283, -0.0819,\n",
      "        -0.1090,  0.0497, -0.0553, -0.0509,  0.1200, -0.0462, -0.0149, -0.0687,\n",
      "        -0.0918, -0.0703, -0.1151, -0.0389,  0.0186, -0.1124,  0.0314, -0.0419,\n",
      "         0.0777, -0.0347, -0.0541,  0.0806, -0.0803, -0.0702, -0.0371, -0.0745,\n",
      "         0.1053,  0.0257, -0.1146, -0.0293,  0.0401,  0.0624,  0.0510, -0.0979,\n",
      "        -0.0051, -0.0869, -0.0479, -0.0515, -0.1065,  0.1111,  0.0288,  0.0256,\n",
      "        -0.0911,  0.0135, -0.0027, -0.1203, -0.0833, -0.1032,  0.0493,  0.0127,\n",
      "        -0.0431,  0.0726,  0.1186, -0.0818,  0.1142,  0.0796, -0.0431, -0.0094,\n",
      "         0.0464,  0.0019,  0.0007,  0.0689,  0.0388, -0.0220,  0.0282, -0.0503,\n",
      "         0.0907,  0.0998, -0.1119,  0.0380, -0.0995, -0.1185,  0.0112,  0.1149,\n",
      "         0.1148,  0.1038, -0.0900,  0.0112,  0.0031, -0.0427,  0.1010,  0.0226,\n",
      "        -0.0901, -0.0975,  0.0315, -0.0287, -0.1201,  0.0418,  0.0356, -0.1196,\n",
      "         0.0994,  0.0916, -0.0903, -0.0938,  0.0078, -0.1130,  0.0735,  0.0169,\n",
      "         0.1036,  0.0299, -0.0761, -0.0110, -0.0310, -0.0678,  0.0460,  0.0131,\n",
      "         0.0848,  0.0275,  0.1002, -0.0249], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "print(list(net.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964dfd42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee5e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f403132",
   "metadata": {},
   "source": [
    "Run a single forward-pass with a random input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3370725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1104, -0.0984, -0.1445, -0.0942,  0.0160, -0.1082, -0.0006, -0.1451,\n",
       "         0.0715,  0.0424,  0.1243,  0.1575, -0.0453, -0.0885,  0.0130,  0.0939,\n",
       "         0.0918,  0.1638, -0.0356, -0.1725,  0.3340, -0.1462, -0.1973,  0.2172,\n",
       "         0.0165,  0.1281,  0.2074, -0.1346,  0.2657,  0.0859, -0.0120, -0.1027,\n",
       "        -0.0274, -0.0470, -0.0260, -0.0894, -0.1786, -0.1254,  0.0611,  0.1438,\n",
       "        -0.0472,  0.0161,  0.1624,  0.0656,  0.0297, -0.1938, -0.1620,  0.0211,\n",
       "        -0.1740,  0.0730,  0.1157, -0.0273,  0.0579,  0.1757, -0.0565,  0.0373,\n",
       "         0.0025, -0.0105,  0.1355, -0.0356, -0.2496, -0.3269,  0.0031,  0.0951,\n",
       "         0.2634,  0.0232, -0.1927,  0.1780,  0.2215, -0.0115, -0.0070,  0.3172,\n",
       "         0.0358,  0.0480,  0.0237, -0.2362,  0.0394,  0.0400,  0.0053, -0.0384,\n",
       "         0.0340,  0.0531, -0.0244,  0.1726, -0.0889, -0.0666,  0.0609,  0.1057,\n",
       "         0.0175,  0.1094,  0.0883,  0.1821,  0.2361,  0.0630,  0.0025,  0.2280,\n",
       "        -0.1272,  0.0185,  0.3134, -0.1612, -0.0179,  0.1308,  0.1608, -0.0253,\n",
       "         0.1493, -0.0646,  0.0619,  0.0751,  0.1409,  0.0722, -0.0170, -0.2591,\n",
       "        -0.0119,  0.2570, -0.1846, -0.0023,  0.1586,  0.0056,  0.1773, -0.2116,\n",
       "        -0.1357,  0.2323,  0.1245,  0.2088,  0.0096,  0.0744, -0.1141,  0.0561,\n",
       "        -0.0381,  0.2338,  0.2820,  0.0172,  0.0043,  0.0705, -0.2345,  0.0289,\n",
       "        -0.3501, -0.0026, -0.1585,  0.1094,  0.0348, -0.1257,  0.0269, -0.1374,\n",
       "        -0.2294,  0.0991,  0.0152, -0.0718, -0.0638,  0.0530,  0.0917, -0.0226,\n",
       "         0.0653, -0.1182,  0.1099, -0.0099,  0.3332,  0.0560, -0.0334, -0.1768,\n",
       "         0.0758,  0.1108, -0.0548, -0.2677,  0.1005,  0.0910,  0.1268, -0.0457,\n",
       "         0.0726, -0.0963, -0.0449, -0.1530, -0.0054,  0.0393, -0.0527, -0.0478,\n",
       "        -0.1670, -0.2986, -0.2253, -0.0890,  0.1753, -0.1571, -0.0340,  0.1161,\n",
       "        -0.0690, -0.1549, -0.0713,  0.1848, -0.1905,  0.0877,  0.0798,  0.1392,\n",
       "         0.2459,  0.0050,  0.1839,  0.2136, -0.1274,  0.1339, -0.2962,  0.0287,\n",
       "        -0.2391,  0.1372, -0.0328, -0.1608,  0.3387,  0.0652,  0.0768, -0.0283,\n",
       "        -0.2055, -0.1116,  0.1266, -0.0510, -0.0332, -0.2086,  0.1633, -0.3377,\n",
       "        -0.1756, -0.0378, -0.2207,  0.0114, -0.2129,  0.2336, -0.0536,  0.0967,\n",
       "         0.1023, -0.0126, -0.0337,  0.0130, -0.2350,  0.0880, -0.0975,  0.1713,\n",
       "         0.2776,  0.1194, -0.2360, -0.1755, -0.1298, -0.3007, -0.0559,  0.0857,\n",
       "         0.3186, -0.1474, -0.1724, -0.0107, -0.0283,  0.3955, -0.2479, -0.1506,\n",
       "        -0.0908, -0.0134, -0.1514,  0.0859, -0.0047,  0.0308, -0.0777, -0.0119,\n",
       "         0.0986,  0.0851,  0.0654, -0.0764, -0.1331,  0.0920, -0.1314,  0.0744,\n",
       "        -0.3159,  0.3425, -0.3045, -0.1517, -0.0430,  0.3204,  0.1828, -0.1019,\n",
       "        -0.0152, -0.2540, -0.0093, -0.0215,  0.1645,  0.0566,  0.0936,  0.1414,\n",
       "        -0.1551, -0.1107,  0.2064,  0.0481, -0.2421,  0.0529,  0.0038, -0.0724,\n",
       "        -0.0847, -0.0459, -0.2216,  0.2134,  0.0705, -0.1935,  0.0735, -0.0786,\n",
       "         0.0902, -0.0123,  0.2708,  0.0665, -0.0206,  0.1049,  0.1252,  0.1093,\n",
       "         0.0481,  0.2826, -0.0349, -0.0776, -0.0086,  0.0976,  0.0178, -0.0791,\n",
       "        -0.0992,  0.1842, -0.0328, -0.0863,  0.0654,  0.0653,  0.1036, -0.1990,\n",
       "        -0.1212,  0.1558, -0.1195, -0.1243,  0.0981,  0.0073, -0.0451, -0.2806,\n",
       "         0.0628, -0.0270,  0.0648,  0.2576,  0.0018, -0.2459,  0.0661, -0.1728,\n",
       "         0.1618, -0.0293, -0.1267,  0.0056,  0.0040, -0.0577,  0.2509,  0.1974,\n",
       "         0.1641,  0.0624,  0.0142,  0.0640, -0.2164, -0.0174, -0.0817,  0.1660,\n",
       "         0.0081, -0.2760, -0.0594, -0.1815, -0.2678,  0.0396,  0.0645, -0.0236,\n",
       "        -0.0266,  0.2625,  0.2178, -0.2905, -0.0035,  0.0595,  0.0864, -0.1184,\n",
       "         0.0973, -0.0615,  0.1506,  0.1191, -0.0030,  0.1601,  0.0864,  0.0981,\n",
       "        -0.1625, -0.0248, -0.0616, -0.1541, -0.2242, -0.1529,  0.1854,  0.0757,\n",
       "         0.1014,  0.2486,  0.2247,  0.0944,  0.0603, -0.2451,  0.0837, -0.0726,\n",
       "        -0.3194, -0.1249,  0.2512,  0.1044,  0.0645,  0.1319,  0.0387, -0.2066,\n",
       "        -0.0384, -0.0819, -0.0934, -0.1921, -0.0167, -0.0390,  0.2489,  0.0393,\n",
       "         0.0740,  0.0868,  0.1249, -0.0493,  0.0327, -0.0452,  0.2055, -0.0773,\n",
       "         0.0854,  0.0778,  0.1801, -0.1903], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(torch.rand(42))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d2cb7",
   "metadata": {},
   "source": [
    "Define a `nn.MSELoss` and a random target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d50abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = net(torch.rand(42))\n",
    "target = torch.randn(420)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1983de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39785fbe",
   "metadata": {},
   "source": [
    "Compute the loss and run backpropagation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53d5cc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0525, grad_fn=<MseLossBackward0>)\n",
      "None\n",
      "None\n",
      "tensor([-0.0024,  0.0000, -0.0013,  0.0037,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0044,  0.0000,  0.0000,  0.0000, -0.0020,  0.0089,  0.0090,  0.0121,\n",
      "         0.0000,  0.0000, -0.0060, -0.0057,  0.0028,  0.0000,  0.0000,  0.0000,\n",
      "         0.0038,  0.0000,  0.0000,  0.0000,  0.0000,  0.0039,  0.0045,  0.0000,\n",
      "         0.0000, -0.0023,  0.0000,  0.0004,  0.0053,  0.0000,  0.0069,  0.0000,\n",
      "         0.0000,  0.0000,  0.0174,  0.0000,  0.0000,  0.0101, -0.0060,  0.0000,\n",
      "         0.0000,  0.0058,  0.0059,  0.0000,  0.0000,  0.0079,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0043,  0.0074,  0.0000,\n",
      "         0.0000, -0.0112, -0.0017,  0.0000,  0.0073])\n"
     ]
    }
   ],
   "source": [
    "loss = criterion(output, target)\n",
    "print(loss)\n",
    "\n",
    "print(net.l1.bias.grad)\n",
    "\n",
    "net.zero_grad()\n",
    "print(net.l1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "print(net.l1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e278bd02",
   "metadata": {},
   "source": [
    "Update the parameters of your network with a learning rate of 0.01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fe16c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for p in net.parameters():\n",
    "    p.data.sub_(p.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927bd19f",
   "metadata": {},
   "source": [
    "Use the `AdamOptimizer` instead to update your parameters (see the [torch.optim documentation](https://pytorch.org/docs/stable/optim.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "054db4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "optimizer.zero_grad()\n",
    "output = net(torch.rand(42))\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
